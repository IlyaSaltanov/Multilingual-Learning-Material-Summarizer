name: CI/CD Pipeline

on:
  push:
    branches: [main, master]
    paths-ignore:
      - 'docs/**'
      - '**.md'
  pull_request:
    branches: [main, master]
  
  workflow_dispatch:
    inputs:
      run_extensive_tests:
        description: 'Run extensive tests'
        required: false
        default: false
        type: boolean
      generate_report:
        description: 'Generate test report'
        required: false
        default: true
        type: boolean
  
  schedule:
    - cron: '0 8 * * *'

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  quality-check:
    name: Code Quality Check
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python 3.11
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install linting tools
        run: |
          python -m pip install --upgrade pip
          pip install flake8 black pylint

      - name: Check code formatting with Black
        run: |
          black --check src/ tests/ || echo "Code formatting issues found (not failing workflow)"

      - name: Lint with flake8
        run: |
          flake8 src/ --count --select=E9,F63,F7,F82 --show-source --statistics || true
          flake8 src/ --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics

      - name: Lint with pylint
        run: |
          pylint --disable=all --enable=E,W src/ || true

  test:
    name: Run Tests
    runs-on: ubuntu-latest
    needs: quality-check

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python 3.11
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          python -m nltk.downloader punkt

      - name: Run basic tests
        run: |
          python -m pytest tests/ -v --tb=short

      - name: Run tests with coverage
        if: ${{ github.event.inputs.run_extensive_tests == 'true' || github.event_name == 'schedule' }}
        run: |
          pip install pytest-cov
          python -m pytest tests/ --cov=src --cov-report=xml --cov-report=html

      - name: Upload coverage reports
        uses: actions/upload-artifact@v4
        if: ${{ github.event.inputs.run_extensive_tests == 'true' || github.event_name == 'schedule' }}
        with:
          name: coverage-report
          path: htmlcov/

  performance-test:
    name: Performance Test
    runs-on: ubuntu-latest
    needs: test
    if: ${{ github.event.inputs.run_extensive_tests == 'true' || github.event_name == 'schedule' }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python 3.11
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          python -m nltk.downloader punkt

      - name: Run performance tests
        run: |
          python -c "
import sys
sys.path.insert(0, 'src')
from summarizer import TextSummarizer
import time

text = '''Artificial intelligence (AI) is intelligence demonstrated by machines, as opposed to natural intelligence displayed by animals including humans. Leading AI textbooks define the field as the study of intelligent agents: any system that perceives its environment and takes actions that maximize its chance of achieving its goals.'''

summarizer = TextSummarizer()

# Warm up
summarizer.summarize_extractive(text, 'en', 30)

# Performance test
start = time.time()
for _ in range(10):
    summary = summarizer.summarize_extractive(text, 'en', 30)
end = time.time()

print('ðŸš€ Performance Test Results ðŸš€')
print('=' * 40)
print(f'â±ï¸  Time for 10 summaries: {end-start:.2f} seconds')
print(f'ðŸ“Š Average time per summary: {(end-start)/10:.3f} seconds')
print(f'ðŸ“ Original length: {len(text.split())} words')
print(f'âœ‚ï¸  Summary length: {len(summary.split())} words')
reduction = 100 - (len(summary.split()) / len(text.split()) * 100)
print(f'ðŸ“‰ Reduction: {reduction:.1f}%')
print('=' * 40)
"

      - name: Save performance metrics
        run: |
          echo "PERFORMANCE_METRICS=$(date +%Y-%m-%d)" >> $GITHUB_ENV
          mkdir -p metrics
          echo "Performance Test - $(date)" > metrics/performance.txt
          echo "Branch: ${{ github.ref }}" >> metrics/performance.txt
          echo "Commit: ${{ github.sha }}" >> metrics/performance.txt

  generate-report:
    name: Generate Daily Report
    runs-on: ubuntu-latest
    needs: test
    if: ${{ github.event_name == 'schedule' || github.event.inputs.generate_report == 'true' }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python 3.11
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pandas

      - name: Generate daily statistics
        run: |
          python -c "
import sys
sys.path.insert(0, 'src')
import pandas as pd
from datetime import datetime

try:
    from summarizer import TextSummarizer
    from language_detector import LanguageDetector
    
    samples = [
        {'text': 'Artificial intelligence is transforming industries worldwide. AI applications are diverse.', 'lang': 'en'},
        {'text': 'Machine learning allows computers to learn from data. This is important technology.', 'lang': 'en'},
        {'text': 'Natural language processing helps computers understand human language.', 'lang': 'en'}
    ]
    
    summarizer = TextSummarizer()
    detector = LanguageDetector()
    
    results = []
    for sample in samples:
        summary = summarizer.summarize_extractive(sample['text'], sample['lang'], 30)
        detected = detector.detect_language(sample['text'])
        original_words = len(sample['text'].split())
        summary_words = len(summary.split())
        reduction = 100 - (summary_words / original_words * 100) if original_words > 0 else 0
        
        results.append({
            'language': sample['lang'],
            'detected_language': detected['language'],
            'detected_confidence': detected['confidence'],
            'original_length': original_words,
            'summary_length': summary_words,
            'reduction_percent': reduction,
            'timestamp': datetime.now().isoformat()
        })
    
    # Save to CSV
    df = pd.DataFrame(results)
    df.to_csv('daily_report.csv', index=False)
    
    print('ðŸ“Š Daily Report Generated:')
    print(df.to_string())
    
    # Create markdown report
    with open('DAILY_REPORT.md', 'w') as f:
        f.write('# ðŸ“ˆ Daily Summary Report\n\n')
        f.write(f'**Generated:** {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}\n\n')
        f.write('## ðŸ“‹ Performance Metrics\n\n')
        f.write('| Language | Detected | Confidence | Original | Summary | Reduction |\n')
        f.write('|----------|----------|------------|----------|---------|-----------|\n')
        for _, row in df.iterrows():
            f.write(f'| {row[\"language\"]} | {row[\"detected_language\"]} | {row[\"detected_confidence\"]:.2f} | ')
            f.write(f'{row[\"original_length\"]} | {row[\"summary_length\"]} | {row[\"reduction_percent\"]:.1f}% |\n')
        
        avg_reduction = df['reduction_percent'].mean()
        total_original = df['original_length'].sum()
        total_summary = df['summary_length'].sum()
        
        f.write(f'\n**ðŸ“Š Summary Statistics:**\n')
        f.write(f'- **Average Reduction:** {avg_reduction:.1f}%\n')
        f.write(f'- **Total Words Processed:** {total_original}\n')
        f.write(f'- **Total Words in Summaries:** {total_summary}\n')
        f.write(f'- **Total Savings:** {total_original - total_summary} words\n')
        
        f.write(f'\n---\n')
        f.write(f'*Report generated automatically by GitHub Actions*\n')
    
    print('âœ… Report saved to DAILY_REPORT.md')
    
except Exception as e:
    print(f'âŒ Error generating report: {e}')
    import traceback
    traceback.print_exc()
    
    # Create minimal report on error
    with open('DAILY_REPORT.md', 'w') as f:
        f.write('# ðŸ“ˆ Daily Summary Report\n\n')
        f.write(f'**Generated:** {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}\n\n')
        f.write('## âš ï¸ Report Generation Failed\n\n')
        f.write('There was an error generating the daily report.\n')
        f.write('Check workflow logs for details.\n\n')
        f.write(f'Error: {str(e)}\n')
"

      - name: Commit and push report
        if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master'
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add daily_report.csv DAILY_REPORT.md 2>/dev/null || echo "Files not found"
          if git diff --quiet && git diff --staged --quiet; then
            echo "No changes to commit"
          else
            git commit -m "ðŸ“Š Update daily report $(date +%Y-%m-%d)" || echo "Commit failed"
            git push origin HEAD:${{ github.ref }} || echo "Push failed, continuing..."
          fi

      - name: Upload report artifacts
        uses: actions/upload-artifact@v4
        with:
          name: daily-report-$(date +%Y-%m-%d)
          path: |
            daily_report.csv
            DAILY_REPORT.md

  deploy-docs:
    name: Deploy Documentation
    runs-on: ubuntu-latest
    needs: test
    if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python 3.11
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install mkdocs mkdocs-material

      - name: Generate documentation
        run: |
          mkdir -p docs
          
          # Create main documentation
          cat > docs/index.md << 'EOF'
# ðŸŒ Multilingual Summarizer

AI-powered text summarization tool supporting multiple languages.

## Features
- Summarize text in English, Russian, and German
- Auto language detection
- Configurable compression levels (20%, 30%, 50%)
- Detailed statistics and metrics

## API Usage
Send POST request to `/summarize` with JSON body:

```json
{
  "text": "Your text here...",
  "compression": 30,
  "language": "auto"
}